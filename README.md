### Hi there ðŸ‘‹

I'm Mahdi, a fellow data geek with 9 years of experience in the data space. Throughout my career, I wore various hats on the engineering side (data engineer, tech lead, data architect, and ML Ops engineer) before switching to product management - I'm currently Head of Product at Sifflet, a data observability B2B SaaS. Before transitioning to product, I mainly worked on designing and building petabyte-scale data platforms. I'm very passionate about open-source projects and enjoy working with data and designing scalable solutions. You can also read my content on [Medium](https://mahdiqb.medium.com/) and via [the Data Espresso newsletter](https://dataespresso.substack.com/).


### The technologies I'm most familiar with:
- Apache Spark (and larger Databricks ecosystem): I used it on a daily basis for nearly five years (and so we know each other pretty well).
- dbt: It's the tool I currently work with the most. At Zendesk, I added dbt to our data stack and worked on defining and implementing standards, frameworks, and automation to better leverage it at scale. ([Article from the Zendesk Engineering blog](https://zendesk.engineering/dbt-at-zendesk-part-i-setting-foundations-for-scalability-34b55e6a6aa1))
- Snowflake: Was part of the core team that worked on transitioning from BigQuery to Snowflake at Zendesk.
- AWS Ecosystem: Worked on it for 3 years, for various data and ML projects (mostly worked with Glue, EMR, Athena, ECS, SageMaker, Redshift, and the AWS CI/CD stack).
- GCP Ecosystem: Worked on it for 3 years, mostly everything BigQuery and GKE.
- Hadoop: Worked with Hadoop data lakes for two and a half years (it was the ecosystem that first introduced me to distributed systems and the paradigms/concepts behind them).
- Other notable projects/tools: Apache Superset, Apache Airflow, Apache Zeppelin, Apache Hive, Dremio, Jupyter, and D3.js.
- Languages I'm fluent in: Python, Java, and -obviously- SQL.
- Other languages I used in the past: C++, C#, JavaScript (Angular, Node.js), and HTML+CSS.
- IaC: Terraform and CloudFormation.


### Notable published work:
- [End-to-End Batch Data Pipeline with Spark](https://www.manning.com/liveprojectseries/batch-data-pipeline-with-spark): A series of four projects that I authored for Manning Publications as part of their liveProjects platform. The series goes through the different steps of building an end-to-end Big Data pipeline. Learners get to use Apache Spark, Delta Lake, and Apache Superset.
- [Building an End-to-End Open-Source Modern Data Platform](https://towardsdatascience.com/building-an-end-to-end-open-source-modern-data-platform-c906be2f31bd): Proposes an exhaustive design (accompanied by the necessary Infrastructure-as-Code) to build a modern data platform solely using open-source projects and the resources offered by cloud providers.
- [Writing design docs for data pipelines](https://towardsdatascience.com/writing-design-docs-for-data-pipelines-d49550f95580): Exploring the what, why, and how of design docs for data components â€” and why they matter.
- [Data Modeling for Data Products: A Practical Guide](https://medium.com/data-engineer-things/data-modeling-for-data-products-a-practical-guide-2db003cc7e72): A set of principles and techniques/frameworks to apply data modeling best practices when shipping data products.
- [Navigating Your Career Transition in Tech: A Practical Roadmap](https://dataespresso.substack.com/p/navigating-your-career-transition): A practical guide to a successful career pivot in tech: from making the decision to thriving in your new role.
- [Data Modeling Techniques for the Post-Modern Data Stack](https://medium.com/towards-data-science/data-modeling-techniques-for-the-post-modern-data-stack-03fc2e4a210c): A set of generic techniques and principles to design a robust, cost-efficient, and scalable data model for your post-modern data stack.
- [Navigating Your Data Platformâ€™s Growing Pains: A Path from Data Mess to Data Mesh](https://towardsdatascience.com/navigating-your-data-platforms-growing-pains-a-path-from-data-mess-to-data-mesh-c16df72f5463): A set of strategies and guiding principles to scale your data platform while maximizing its business impact efficiently.
- [A Simple (Yet Effective) Approach to Implementing Unit Tests for dbt Models](https://towardsdatascience.com/a-simple-yet-effective-approach-to-implementing-unit-tests-for-dbt-models-da2583ea8e79): Proposes an innovative unit testing approach for dbt models - relying on standards and dbt best practices.
- [Creating Notebook-based Dynamic Dashboards](https://towardsdatascience.com/creating-notebook-based-dynamic-dashboards-91f936adc6f3): A design (accompanied by a POC) in which notebooks are leveraged to generate dynamic dashboards, to support a Google-like metadata search engine.

### Notable presentations and podcasts:
- Data Innovation Summit 2023: [The Data Engineer's Guide to Data Quality Testing: The Fun, Easy, and Scalable Way](https://hyperight.com/data-engineers-guide-to-data-quality-testing-easy-and-scalable-way-mahdi-karabiben-zendesk/)
- Big Data Expo 2022: [A Practical Case Study for Data Engineers: Performing Data Quality at Scale](https://www.bigdata-expo.nl/nl/programma/practical-case-study-data-engineers-performing-data-quality-scale)
- The Modern Data Show (S01E02): [The third wave of data technologies](https://www.moderndatastack.xyz/podcast/s01-e02-the-third-wave-of-data-technologies-with-mahdi-karabiben-auex)
- Product-Led-Growth Disrupt Summit 2025: [From Haystack to Insights: Three Ways AI is Transforming Product Analytics
](https://www.youtube.com/watch?v=sG0oCwxHw3A)
